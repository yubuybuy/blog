#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç³»ç»Ÿæ€§èƒ½ä¼˜åŒ–å·¥å…·
"""

import asyncio
import json
import sqlite3
import sys
from datetime import datetime, timedelta
from pathlib import Path
import time


class SystemOptimizer:
    """ç³»ç»Ÿä¼˜åŒ–å™¨"""

    def __init__(self):
        self.db_path = "data/netdisk_links.db"
        self.optimization_results = {}

    async def optimize_database(self):
        """ä¼˜åŒ–æ•°æ®åº“"""
        print("ğŸ”§ ä¼˜åŒ–æ•°æ®åº“...")

        try:
            with sqlite3.connect(self.db_path) as conn:
                # 1. åˆ†ææ•°æ®åº“å¤§å°
                result = conn.execute("PRAGMA page_count").fetchone()
                page_count = result[0] if result else 0

                result = conn.execute("PRAGMA page_size").fetchone()
                page_size = result[0] if result else 0

                db_size_mb = (page_count * page_size) / 1024 / 1024

                # 2. åˆ›å»ºç´¢å¼•ä¼˜åŒ–æŸ¥è¯¢
                indexes = [
                    "CREATE INDEX IF NOT EXISTS idx_status ON netdisk_links(status)",
                    "CREATE INDEX IF NOT EXISTS idx_platform ON netdisk_links(platform)",
                    "CREATE INDEX IF NOT EXISTS idx_created_at ON netdisk_links(created_at)",
                    "CREATE INDEX IF NOT EXISTS idx_chat_id ON netdisk_links(chat_id)",
                    "CREATE INDEX IF NOT EXISTS idx_status_platform ON netdisk_links(status, platform)"
                ]

                for index_sql in indexes:
                    conn.execute(index_sql)

                # 3. æ¸…ç†é‡å¤è®°å½•
                duplicate_query = '''
                    DELETE FROM netdisk_links
                    WHERE id NOT IN (
                        SELECT MIN(id)
                        FROM netdisk_links
                        GROUP BY url, platform
                    )
                '''
                cursor = conn.execute(duplicate_query)
                duplicates_removed = cursor.rowcount

                # 4. æ¸…ç†è¿‡æœŸå¤±è´¥è®°å½•
                cutoff_date = datetime.now() - timedelta(days=7)
                cleanup_query = '''
                    DELETE FROM netdisk_links
                    WHERE status = 'failed'
                    AND created_at < ?
                '''
                cursor = conn.execute(cleanup_query, (cutoff_date.isoformat(),))
                old_failed_removed = cursor.rowcount

                # 5. é‡å»ºæ•°æ®åº“ï¼ˆå‹ç¼©ï¼‰
                conn.execute("VACUUM")

                # 6. åˆ†æè¡¨ç»Ÿè®¡ä¿¡æ¯
                conn.execute("ANALYZE")

                self.optimization_results["æ•°æ®åº“ä¼˜åŒ–"] = {
                    "åŸå§‹å¤§å°MB": round(db_size_mb, 2),
                    "æ¸…ç†é‡å¤è®°å½•": duplicates_removed,
                    "æ¸…ç†è¿‡æœŸå¤±è´¥è®°å½•": old_failed_removed,
                    "åˆ›å»ºç´¢å¼•": len(indexes),
                    "çŠ¶æ€": "âœ… å®Œæˆ"
                }

                print(f"  âœ… æ•°æ®åº“ä¼˜åŒ–å®Œæˆ")
                print(f"    ğŸ“Š åŸå§‹å¤§å°: {db_size_mb:.2f}MB")
                print(f"    ğŸ—‘ï¸ æ¸…ç†é‡å¤è®°å½•: {duplicates_removed}æ¡")
                print(f"    ğŸ—‘ï¸ æ¸…ç†è¿‡æœŸå¤±è´¥è®°å½•: {old_failed_removed}æ¡")
                print(f"    ğŸ“ˆ åˆ›å»ºç´¢å¼•: {len(indexes)}ä¸ª")

        except Exception as e:
            self.optimization_results["æ•°æ®åº“ä¼˜åŒ–"] = {
                "çŠ¶æ€": "âŒ å¤±è´¥",
                "é”™è¯¯": str(e)
            }
            print(f"  âŒ æ•°æ®åº“ä¼˜åŒ–å¤±è´¥: {e}")

    async def optimize_logs(self):
        """ä¼˜åŒ–æ—¥å¿—æ–‡ä»¶"""
        print("ğŸ”§ ä¼˜åŒ–æ—¥å¿—æ–‡ä»¶...")

        try:
            logs_dir = Path("logs")
            if not logs_dir.exists():
                logs_dir.mkdir()

            total_size = 0
            cleaned_files = 0
            archived_files = 0

            for log_file in logs_dir.glob("*.log"):
                file_size = log_file.stat().st_size
                total_size += file_size

                # å¦‚æœæ—¥å¿—æ–‡ä»¶è¶…è¿‡10MBï¼Œè¿›è¡Œå½’æ¡£
                if file_size > 10 * 1024 * 1024:  # 10MB
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    archive_name = f"{log_file.stem}_{timestamp}.log"
                    archive_path = logs_dir / "archive" / archive_name

                    # åˆ›å»ºå½’æ¡£ç›®å½•
                    archive_path.parent.mkdir(exist_ok=True)

                    # ç§»åŠ¨æ–‡ä»¶åˆ°å½’æ¡£
                    log_file.rename(archive_path)
                    archived_files += 1

            # æ¸…ç†è¶…è¿‡30å¤©çš„å½’æ¡£æ–‡ä»¶
            archive_dir = logs_dir / "archive"
            if archive_dir.exists():
                cutoff_time = time.time() - (30 * 24 * 3600)  # 30å¤©å‰

                for archive_file in archive_dir.glob("*.log"):
                    if archive_file.stat().st_mtime < cutoff_time:
                        archive_file.unlink()
                        cleaned_files += 1

            self.optimization_results["æ—¥å¿—ä¼˜åŒ–"] = {
                "æ€»å¤§å°MB": round(total_size / 1024 / 1024, 2),
                "å½’æ¡£æ–‡ä»¶": archived_files,
                "æ¸…ç†æ–‡ä»¶": cleaned_files,
                "çŠ¶æ€": "âœ… å®Œæˆ"
            }

            print(f"  âœ… æ—¥å¿—ä¼˜åŒ–å®Œæˆ")
            print(f"    ğŸ“Š æ€»å¤§å°: {total_size / 1024 / 1024:.2f}MB")
            print(f"    ğŸ“¦ å½’æ¡£æ–‡ä»¶: {archived_files}ä¸ª")
            print(f"    ğŸ—‘ï¸ æ¸…ç†æ–‡ä»¶: {cleaned_files}ä¸ª")

        except Exception as e:
            self.optimization_results["æ—¥å¿—ä¼˜åŒ–"] = {
                "çŠ¶æ€": "âŒ å¤±è´¥",
                "é”™è¯¯": str(e)
            }
            print(f"  âŒ æ—¥å¿—ä¼˜åŒ–å¤±è´¥: {e}")

    async def optimize_config(self):
        """ä¼˜åŒ–é…ç½®æ–‡ä»¶"""
        print("ğŸ”§ ä¼˜åŒ–é…ç½®æ–‡ä»¶...")

        try:
            optimizations = []

            # æ£€æŸ¥Telegramé…ç½®
            config_path = "config/telegram_config.json"
            if Path(config_path).exists():
                with open(config_path, 'r', encoding='utf-8') as f:
                    config = json.load(f)

                # ä¼˜åŒ–è®¾ç½®
                settings = config.get('settings', {})

                # å»ºè®®ä¼˜åŒ–é¡¹
                suggestions = {
                    'max_links_per_message': 5,  # å‡å°‘æ¯æ¡æ¶ˆæ¯å¤„ç†çš„é“¾æ¥æ•°
                    'auto_extract_password': True,  # è‡ªåŠ¨æå–å¯†ç 
                    'batch_size': 3,  # æ‰¹é‡å¤„ç†å¤§å°
                    'retry_failed_after_hours': 24  # é‡è¯•å¤±è´¥é“¾æ¥çš„é—´éš”
                }

                updated = False
                for key, value in suggestions.items():
                    if key not in settings:
                        settings[key] = value
                        optimizations.append(f"æ·»åŠ {key}è®¾ç½®")
                        updated = True

                if updated:
                    config['settings'] = settings
                    with open(config_path, 'w', encoding='utf-8') as f:
                        json.dump(config, f, ensure_ascii=False, indent=2)

            # åˆ›å»ºæ€§èƒ½é…ç½®æ–‡ä»¶
            performance_config = {
                "database": {
                    "connection_timeout": 30,
                    "query_timeout": 10,
                    "max_connections": 5
                },
                "transfer": {
                    "concurrent_transfers": 3,
                    "retry_attempts": 3,
                    "retry_delay_seconds": 5,
                    "batch_delay_seconds": 2
                },
                "monitoring": {
                    "health_check_interval": 300,
                    "log_rotation_days": 30,
                    "alert_thresholds": {
                        "failed_rate_percent": 50,
                        "memory_usage_mb": 500
                    }
                }
            }

            perf_config_path = "config/performance_config.json"
            with open(perf_config_path, 'w', encoding='utf-8') as f:
                json.dump(performance_config, f, ensure_ascii=False, indent=2)

            optimizations.append("åˆ›å»ºæ€§èƒ½é…ç½®æ–‡ä»¶")

            self.optimization_results["é…ç½®ä¼˜åŒ–"] = {
                "ä¼˜åŒ–é¡¹": optimizations,
                "çŠ¶æ€": "âœ… å®Œæˆ"
            }

            print(f"  âœ… é…ç½®ä¼˜åŒ–å®Œæˆ")
            for opt in optimizations:
                print(f"    ğŸ“ {opt}")

        except Exception as e:
            self.optimization_results["é…ç½®ä¼˜åŒ–"] = {
                "çŠ¶æ€": "âŒ å¤±è´¥",
                "é”™è¯¯": str(e)
            }
            print(f"  âŒ é…ç½®ä¼˜åŒ–å¤±è´¥: {e}")

    async def create_maintenance_script(self):
        """åˆ›å»ºç»´æŠ¤è„šæœ¬"""
        print("ğŸ”§ åˆ›å»ºç»´æŠ¤è„šæœ¬...")

        try:
            maintenance_script = '''#!/bin/bash
# ç³»ç»Ÿç»´æŠ¤è„šæœ¬
# å®šæœŸè¿è¡Œæ­¤è„šæœ¬è¿›è¡Œç³»ç»Ÿç»´æŠ¤

echo "ğŸ”§ å¼€å§‹ç³»ç»Ÿç»´æŠ¤..."

# 1. æ•°æ®åº“ä¼˜åŒ–
echo "ä¼˜åŒ–æ•°æ®åº“..."
python3 scripts/optimize_system.py database

# 2. æ¸…ç†æ—¥å¿—
echo "æ¸…ç†æ—¥å¿—..."
python3 scripts/optimize_system.py logs

# 3. ç³»ç»Ÿå¥åº·æ£€æŸ¥
echo "ç³»ç»Ÿå¥åº·æ£€æŸ¥..."
python3 scripts/monitor.py check

# 4. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
echo "æ¸…ç†ä¸´æ—¶æ–‡ä»¶..."
find . -name "*.tmp" -delete
find . -name "*.pyc" -delete
find . -name "__pycache__" -type d -exec rm -rf {} + 2>/dev/null || true

echo "âœ… ç³»ç»Ÿç»´æŠ¤å®Œæˆ"
'''

            script_path = "scripts/maintenance.sh"
            with open(script_path, 'w', encoding='utf-8') as f:
                f.write(maintenance_script)

            # è®¾ç½®æ‰§è¡Œæƒé™ (Unixç³»ç»Ÿ)
            import os
            os.chmod(script_path, 0o755)

            # åˆ›å»ºWindowsæ‰¹å¤„ç†æ–‡ä»¶
            windows_script = '''@echo off
REM ç³»ç»Ÿç»´æŠ¤è„šæœ¬ - Windowsç‰ˆæœ¬

echo ğŸ”§ å¼€å§‹ç³»ç»Ÿç»´æŠ¤...

REM 1. æ•°æ®åº“ä¼˜åŒ–
echo ä¼˜åŒ–æ•°æ®åº“...
python scripts\\optimize_system.py database

REM 2. æ¸…ç†æ—¥å¿—
echo æ¸…ç†æ—¥å¿—...
python scripts\\optimize_system.py logs

REM 3. ç³»ç»Ÿå¥åº·æ£€æŸ¥
echo ç³»ç»Ÿå¥åº·æ£€æŸ¥...
python scripts\\monitor.py check

REM 4. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
echo æ¸…ç†ä¸´æ—¶æ–‡ä»¶...
del /S /Q *.tmp 2>nul
del /S /Q *.pyc 2>nul
for /D /R %%d in (__pycache__) do @if exist "%%d" rd /S /Q "%%d"

echo âœ… ç³»ç»Ÿç»´æŠ¤å®Œæˆ
pause
'''

            windows_script_path = "scripts/maintenance.bat"
            with open(windows_script_path, 'w', encoding='utf-8') as f:
                f.write(windows_script)

            self.optimization_results["ç»´æŠ¤è„šæœ¬"] = {
                "åˆ›å»ºæ–‡ä»¶": [script_path, windows_script_path],
                "çŠ¶æ€": "âœ… å®Œæˆ"
            }

            print(f"  âœ… ç»´æŠ¤è„šæœ¬åˆ›å»ºå®Œæˆ")
            print(f"    ğŸ“„ Linux/Mac: {script_path}")
            print(f"    ğŸ“„ Windows: {windows_script_path}")

        except Exception as e:
            self.optimization_results["ç»´æŠ¤è„šæœ¬"] = {
                "çŠ¶æ€": "âŒ å¤±è´¥",
                "é”™è¯¯": str(e)
            }
            print(f"  âŒ ç»´æŠ¤è„šæœ¬åˆ›å»ºå¤±è´¥: {e}")

    async def generate_optimization_report(self):
        """ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š"""
        print("\nğŸ“Š ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š...")

        report = {
            "timestamp": datetime.now().isoformat(),
            "optimizations": self.optimization_results
        }

        # ä¿å­˜æŠ¥å‘Š
        report_path = "logs/optimization_report.json"
        Path("logs").mkdir(exist_ok=True)

        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)

        # ç»Ÿè®¡
        total_optimizations = len(self.optimization_results)
        successful = len([r for r in self.optimization_results.values()
                         if r.get("çŠ¶æ€") == "âœ… å®Œæˆ"])

        print("="*50)
        print("ğŸ“Š ç³»ç»Ÿä¼˜åŒ–æŠ¥å‘Š")
        print("="*50)
        print(f"ğŸ¯ æ€»ä¼˜åŒ–é¡¹: {total_optimizations}")
        print(f"âœ… æˆåŠŸ: {successful}")
        print(f"âŒ å¤±è´¥: {total_optimizations - successful}")

        print("\nğŸ“‹ è¯¦ç»†ç»“æœ:")
        for name, result in self.optimization_results.items():
            print(f"  {result['çŠ¶æ€']} {name}")
            if "é”™è¯¯" in result:
                print(f"    ğŸ”´ {result['é”™è¯¯']}")

        print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Š: {report_path}")
        print("="*50)

    async def run_optimization(self, mode="all"):
        """è¿è¡Œä¼˜åŒ–"""
        print("ğŸš€ å¼€å§‹ç³»ç»Ÿä¼˜åŒ–...")

        if mode == "all" or mode == "database":
            await self.optimize_database()

        if mode == "all" or mode == "logs":
            await self.optimize_logs()

        if mode == "all" or mode == "config":
            await self.optimize_config()

        if mode == "all":
            await self.create_maintenance_script()

        await self.generate_optimization_report()

        print("ğŸ‰ ç³»ç»Ÿä¼˜åŒ–å®Œæˆ!")


async def main():
    """ä¸»å‡½æ•°"""
    mode = sys.argv[1] if len(sys.argv) > 1 else "all"

    if mode not in ["all", "database", "logs", "config"]:
        print("ç”¨æ³•:")
        print("  python optimize_system.py [all|database|logs|config]")
        sys.exit(1)

    optimizer = SystemOptimizer()
    await optimizer.run_optimization(mode)


if __name__ == "__main__":
    asyncio.run(main())